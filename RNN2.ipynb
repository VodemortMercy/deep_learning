{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import nltk\n",
    "import gensim as gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file():#read whole document\n",
    "    file_obj = open('ihavedream','r')\n",
    "    my_text = file_obj.read(-1)\n",
    "    my_text = my_text.replace(',',' ,').replace('.',' . ').replace('\\n\\n','').replace('\"',' \" ').replace('?',' ? ').replace('!',' ! ')\n",
    "    file_obj.close()\n",
    "    return my_text\n",
    "\n",
    "def sent2word(sentences):#convert sentences list to word list but persist order\n",
    "    sent_words = []\n",
    "    for sentence in sentences:\n",
    "        tokenized_text = nltk.word_tokenize(sentence)\n",
    "        sent_words.append(tokenized_text)\n",
    "    return sent_words\n",
    "\n",
    "def word2vector(words,gsmodel):\n",
    "    vec = []\n",
    "    for word in words:\n",
    "        for wor in word:\n",
    "            temp = gsmodel.wv[wor]\n",
    "            vec.append(temp)\n",
    "    return vec\n",
    "def vector2word(vec,gsmodel):\n",
    "    return model.wv.most_similar(positive=vec,topn=1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = read_file()#the whole documents\n",
    "sentences = nltk.sent_tokenize(document)\n",
    "words = sent2word(sentences)\n",
    "model = gs.models.Word2Vec(words, min_count=0,size=100)\n",
    "result = word2vector(words,model)\n",
    "X = result[0:1843-1]\n",
    "Y = result[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc_layer(w,b,inputs):\n",
    "    return tf.add(tf.matmul(inputs,w),b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfX = tf.placeholder(shape=[1,100],dtype=tf.float32,name='tfX')\n",
    "tfY = tf.placeholder(shape=[1,100],dtype=tf.float32,name='tfY')\n",
    "\n",
    "tfW = tf.Variable(tf.constant(0,shape=[100,100],dtype=tf.float32),name='tfW')\n",
    "tfB = tf.Variable(tf.constant(0,shape=[1,100],dtype=tf.float32),name='tfB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnncell = tf.nn.rnn_cell.BasicRNNCell(num_units=100,activation=tf.nn.tanh)\n",
    "h = rnncell.zero_state(1,dtype=tf.float32)\n",
    "output1, h = rnncell.call(tfX,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output2, h2 = rnncell.call(tfX,h)\n",
    "res = fc_layer(tfW,tfB,h2)\n",
    "loss = tf.losses.mean_squared_error(labels=tfY,predictions=res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "init_h = sess.run(h,feed_dict={tfX:X[0].reshape(1,100)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.42027e-05\n",
      "1.38597e-05\n",
      "1.26431e-05\n",
      "1.20042e-05\n",
      "1.18306e-05\n",
      "1.18579e-05\n",
      "1.19835e-05\n",
      "1.21454e-05\n",
      "1.20893e-05\n",
      "1.18902e-05\n",
      "1.14697e-05\n",
      "1.10419e-05\n",
      "1.07333e-05\n",
      "1.05577e-05\n",
      "1.03762e-05\n",
      "1.00369e-05\n",
      "9.7131e-06\n",
      "9.6874e-06\n",
      "9.73182e-06\n",
      "9.72323e-06\n",
      "9.65283e-06\n",
      "9.60429e-06\n",
      "9.83907e-06\n",
      "1.01739e-05\n",
      "1.01545e-05\n",
      "9.92364e-06\n",
      "9.71716e-06\n",
      "9.64616e-06\n",
      "9.74883e-06\n",
      "9.6878e-06\n",
      "9.53443e-06\n",
      "9.45787e-06\n",
      "9.5063e-06\n",
      "9.55342e-06\n",
      "9.57016e-06\n",
      "9.51714e-06\n",
      "9.4594e-06\n",
      "9.42836e-06\n",
      "9.41392e-06\n",
      "9.48922e-06\n",
      "9.60539e-06\n",
      "9.58835e-06\n",
      "9.38794e-06\n",
      "9.17315e-06\n",
      "9.07264e-06\n",
      "9.07983e-06\n",
      "9.12416e-06\n",
      "9.17171e-06\n",
      "9.21392e-06\n",
      "9.34986e-06\n"
     ]
    }
   ],
   "source": [
    "epoch = 50\n",
    "for _ in range(epoch):\n",
    "    result_loss = 0\n",
    "    for i,x in enumerate(X):\n",
    "        if i >= 1:\n",
    "            dictionary = {tfX:X[i].reshape(1,100),tfY:Y[i].reshape(1,100),h:init_h}\n",
    "            init_h = sess.run(h2,feed_dict=dictionary)\n",
    "            sess.run(optimizer,feed_dict=dictionary)\n",
    "            W = sess.run(tfW)\n",
    "            B = sess.run(tfB)\n",
    "            H = init_h\n",
    "            result_loss = sess.run(loss,feed_dict=dictionary)\n",
    "            result_loss += result_loss\n",
    "    print(result_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumary = tf.summary.FileWriter('./test',sess.graph)\n",
    "sumary.close()\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction\n",
    "pred_W = tf.Variable(W)\n",
    "pred_B = tf.Variable(B)\n",
    "pred_H = tf.Variable(H)\n",
    "pred_X = tf.Variable(X[0].reshape(1,100))\n",
    "\n",
    "pred_cell = tf.nn.rnn_cell.BasicRNNCell(num_units=100)\n",
    "pred_output,_ = pred_cell.call(pred_X,pred_H)\n",
    "pred_X_old = fc_layer(pred_W,pred_B,pred_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n",
      "we\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    res_X = sess.run(pred_X_old)\n",
    "    pred_X.load(res_X,session=sess)\n",
    "    pred_wordis = vector2word(res_X,model)\n",
    "    print(pred_wordis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
